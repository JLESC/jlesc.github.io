#
# Official Research Topics in JLESC
#
#
# ## Purpose
#
# - validation of project categories (c.f. `topics` YAML field of projects)
#
#
# ## Identifier Format
#
# no additional restrictions to standard YAML's mappings
#
#
# ## Require Attributes
#
#   title          the name of the kind as rendered on the website
#   desc           a detailed description of the topic; shows up on the website and in the LaTeX
#                  report
#
#
# ## Optional Attributes
#
# -none-
#
#
# ## Notes
#
# - stick to a total line length of 100 characters ................................ this is here ->|
#   For longer text fields (e.g. 'topics') use YAML's "Folded style" [1]:
#
#   johnson_j:
#     ...
#     topics: >
#       a really long description spanning
#       multiple lines
#     ...
#
# [1]: https://en.wikipedia.org/wiki/YAML#Newlines_folded
#

architectures:
  title: Advanced Architectures
  desc: >
    The convergence between HPC, Cloud and bigdata as well as the technology trends, in particular the end of the Moore’s law, call for research in new architecture at the large scale level and at the device level. The convergence between HPC, Cloud and bigdata is a central research topic in the community as shown by the BDEC meetings organized by the leaders of the community and by the orientation taken by vendors (HPC system providers). What type of resources are needed, what architecture, what system software, what programming models, what new applications are some of the questions this convergence raises. The end of the Moore's law is another factor of transformation in the HPC domain. It becomes clear that the CMOS integration progress will come to an end in the mid 2020's. It is also very unlikely that any new technology will provide four decades of progress that CMOS gave us. This opens a very exciting era of research for microarchitecture, system architecture and all the software stack: if performance progress does not come anymore from the technology then architecture and software will play a major role.

apps:
  title: Apps & Mini-Apps
  desc: >
    Science needs and constraints in terms of simulation, analytics, communication and storage are the ultimate drivers of the research in the JLESC. Applications are the tangible instances of scientific problems on which the joint-lab can provide contributions. It is important in the joint-lab to understand trends and anticipate significant evolutions. How to model scientific problems and map them into efficient applications, what type of numerical methods these applications use and what are the attractive numerical methods for future extreme scale systems, what are the motifs (in the sense of Berkeley motifs) used in these applications, are there any new emerging motifs, how new constraints such as data reduction and in-situ data analytics change application design, how to map applications to mini-apps that are more tractable for computer science research purpose are among the questions that the JLESC address in this topic.

storage:
  title: I/O, Storage and In-Situ Processing
  desc: >
    Data communication and storage is becoming the main performance bottleneck for extreme scale systems. File system bandwidth for the largest systems seems plateauing around 1TB/s.  This raises several new problems concerning the I/O infrastructure, the software of the storage system, visualization, how to perform analytics before storing the data produced by the simulation. New research domains have emerged in HPC system the past 2-5 years: Burst buffers, in-situ data analytics, workflows and new abstractions for storage. This topic of the JLESC oversees all these questions considering performance (I/O overheads and interference for example), scalability and reliability as critical.  

ai:
  title: AI for HPC, HPC for AI
  desc: >
    The rapid advancement of artificial intelligence and machine learning is transforming the landscape of high-performance computing, creating a dynamic interplay between the two domains. On the one hand, AI techniques are increasingly used within traditional HPC fields to optimize simulations, improve numerical methods, accelerate data analysis, guide complex parameter simulations, increase the performance of system software and other improvements. On the other hand, large-scale AI models demand extreme-scale resources, driving the development of new system architectures, scheduling strategies, and scalable software frameworks. This dual relationship—AI for HPC and HPC for AI—raises important research questions. For example, how can we best integrate AI into scientific computing pipelines? And how should HPC systems evolve to meet the demands of AI workloads? Addressing these and other questions together within the JLESC will require coordinated innovation across hardware, software, algorithms, workflows and use cases, marking a new frontier for the HPC and AI communities.

qc:
  title: Hybrid HPC-Quantum Computing
  desc: >
    Hybrid quantum computing is emerging as a promising avenue to extend the capabilities of high-performance computing in the post-Moore era. The integration of quantum processors as accelerators within classical HPC systems offers a path toward solving certain classes of problems that are intractable for traditional architectures alone. The hybrid approach raises fundamental questions about how to design systems that effectively combine quantum and classical resources: what kind of hardware and software interfaces are needed, what programming models are effective, and how workloads can be partitioned between classical and quantum components. As quantum hardware matures and becomes increasingly accessible, hybrid quantum computing presents both a challenge and an opportunity for the researchers within the JLESC community—requiring coordinated advances in system architecture, programming models, runtime environments, algorithm design, and application development. These challenges are addressed by this topic.


numerics:
  title: Numerical Methods
  desc: >
    The efficient use of modern HPC systems has become one of the key challenges in computational
    science.
    Top HPC architectures already provide million-way concurrency, and current trends suggest that
    processor counts will continue to grow rapidly.
    There is a broad class of algorithms and methods that are common to several scientific or
    engineering problems.
    Ideally, the development of simulation programs follows a layered design in which generic
    methods are applied to create or extend domain-specific solutions.
    Such methods must therefore exploit the most efficient algorithms or parallel tools to avoid
    becoming computational bottlenecks themselves.
    Within JLESC, the following projects address critical issues in the field of numerical methods
    and algorithms.

resilience:
  title: Resilience
  desc: >
    Resilience is a major roadblock for HPC executions on future exascale systems.
    Projections from current large systems and technology evolution predict errors will happen in
    exascale systems many times per day.
    These errors will propagate and generate various kinds of malfunctions, from simple process
    crashes to result corruptions.
    The past five years have seen extraordinary technical progress in many domains related to
    exascale resilience.
    Several technical options, initially considered inapplicable or unrealistic in the HPC context,
    have demonstrated surprising successes.
    Despite this progress, the exascale resilience problem is not solved, and the community is still
    facing the difficult challenge of ensuring that exascale applications complete and generate
    correct results while running on unstable systems.
    Within JLESC, the following projects address critical issues in the field of resilience and
    fault-tolerant HPC.

perf_tools:
  title: Performance Tools
  desc: >
    Parallel architectures enable to target more complex and ambitious problems each year.
    But in many cases, the achieved performance is far away from what the theoretical values
    promised us.
    Performance analysis tools allow application developers to identify and characterize the
    inefficiencies that caused a poor performance.
    We consider that this analysis must be the first step towards the optimization of an application.
    Optimizing without a previous analysis could be like driving without directions as it could mean
    wasting efforts improving parts of the code that were not the real performance bottlenecks.
    Within JLESC, the following projects address critical issues in the performance tools and analysis.

prog_lang:
  title: Programming Languages and Runtimes
  desc: >
    The community has converged since more than a decade towards the model of MPI+OpenMP. While other programming models have been proposed, ultimately the relevant new features proposed by these models were integrated into MPI (RMA for example) and OpenMP (accelerator directives for example). So it is remarkable that MPI and OpenMP are continuously evolving to adapt to changes in architectures. The next generation of systems and the future Exascale systems pose new problems with the non-volatile memory, many cores CPUs and the needs to manage power, to better load balance the execution and to handle a variety of accelerators. In particular, tasks based programming models and runtimes are attractive and need to be refined for these new systems.
