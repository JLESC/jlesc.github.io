<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Joint Laboratory on Extreme Scale Computing</title>
    <description>The Joint Laboratory for Extreme Scale Computing includes researchers from the French National Institute for Research in Computer Science and Control (INRIA), the University of Illinois at Urbana-Champaign’s Center for Extreme-Scale Computation, the National Center for Supercomputing Applications, Argonne National Laboratory, Barcelona Supercomputing Center, Julich Supercomputing Center and Riken/AICS. The Joint Lab is part of Parallel@Illinois.
</description>
    <link>https://jlesc.github.io/</link>
    <atom:link href="https://jlesc.github.io/feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>Open postdoc positions at ANL</title>
        <description>&lt;p&gt;ANL has an number of open positions for postdocs!&lt;/p&gt;

&lt;!--more--&gt;

&lt;h4 id=&quot;postdoc-datastates---tracking-versioning-and-reuse-of-intermediate-data&quot;&gt;&lt;a href=&quot;https://bit.ly/3lcKCPM&quot;&gt;Postdoc: DataStates - Tracking, Versioning and Reuse of Intermediate Data&lt;/a&gt;&lt;/h4&gt;

&lt;p&gt;Contact: &lt;a href=&quot;bnicolae@anl.gov&quot;&gt;Bogdan Nicolae&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Description: We are exploring a new data model centered around the notion of data states, which are intermediate representations of datasets automatically recorded into a lineage when tagged by applications with hints, constraints and persistency semantics. Such an approach enables the applications to focus on the meaning and properties of their data rather than how to access it, effectively reducing complexity while unlocking high performance and scalability for many use cases: finding and reusing previous intermediate results to explore alternatives, inspecting the evolution of datasets, verifying correctness, etc. This is especially important in the context of deep learning, where there is an acute need for advanced tools that explore many alternative DNN models and/or ensembles to improve accuracy, training speed and ability to generalize/explain a problem.&lt;/p&gt;

&lt;p&gt;Link: &lt;a href=&quot;https://bit.ly/3lcKCPM&quot;&gt;https://bit.ly/3lcKCPM&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;postdocphd-subcontractinternship-rrr-robustness-reconfigurability-reproducibility-for-hpcbdai-workflows&quot;&gt;Postdoc/PhD subcontract/internship: RRR (robustness, reconfigurability, reproducibility) for HPC+BD+AI workflows&lt;/h4&gt;

&lt;p&gt;Contact: &lt;a href=&quot;bnicolae@anl.gov&quot;&gt;Bogdan Nicolae&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Description: We seek three properties (abbreviated RRR) for hybrid workflows composed of HPC, BD, and AI: robustness (gracefully handle failures and other unexpected events);  reconfigurability (dynamically adapt to changing conditions during run-time for optimal performance and scalability); reproducibility (able to replay part or all of a workflow under similar conditions in order to verify the results). In this context, we are exploring novel techniques that exploit relaxed inter-task dependencies to optimize checkpoint-restart strategies (e.g. no need to roll back if enough survivors are in a consistent state, workflow orchestration based on up-to-date overview of behavioral patterns, dynamic reproducibility based on capturing decision provenance.&lt;/p&gt;

&lt;h4 id=&quot;postdocphd-subcontractinternship-deep-learning-oriented-streams-with-revisit-support&quot;&gt;Postdoc/PhD subcontract/internship: Deep Learning-oriented streams with revisit support&lt;/h4&gt;

&lt;p&gt;Description: Modern deep learning is not static: training sets: new training data is constantly arriving. However, DNN models cannot be simply trained incrementally due to the problem of catastrophic forgetting, i.e., bias in favor of newer samples at the expense of older ones. Therefore, old samples need to be persisted and revisited, which is not a pattern the storage solutions used by state-of-the-art approaches (e.g., parallel file systems) are optimized to address. In this context, one idea is to extract representative old samples and combine them with new samples such as to enable unbiased retraining. This internship will explore techniques to achieve this goal while mitigating the I/O performance and scalability issues associated with the constant accumulation of new samples (which slows down I/O performance over time).&lt;/p&gt;

&lt;h3 id=&quot;postdoc-in-the-context-of-the-ecp-project-ai-based-prediction-for-data-reduction-and-interference-avoidance&quot;&gt;Postdoc in the context of the ECP project: AI based prediction for data reduction and interference avoidance.&lt;/h3&gt;

&lt;p&gt;Contact: &lt;a href=&quot;cappello@anl.gov&quot;&gt;Franck Cappello&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Description: The combination of AI and HPC offers new opportunity to improve the performance of scientific applications. How AI can help accelerate HPC operations and ultimately scientific application executions is an important question in this context. The postdoc position will explore how to leverage AI to accelerate data transformations and management in Exascale systems. We list here only 2 examples of potential directions. Other research directions in this context are possible depending on candidate interests and skills. One first potential direction is how to leverage AI to improve data reduction. Recent attempts of using auto-encoders for lossy data reduction are showing promising results. More exploration is needed to better understand and control AI model data reduction performance (ratio, speed, accuracy), potentially in combination with other data reduction techniques. Another potential direction is to explore optimization of asynchronous data movement scheduling between resources of exascale systems. A promising direction is AI based interference avoidance that has already shown positive results on relatively simple cases. How AI based interference avoidance perform on more complex cases and how to optimize it remain open questions.&lt;/p&gt;

&lt;h3 id=&quot;postdoctoral-appointee--heterogeneity-in-high-performance-computing&quot;&gt;&lt;a href=&quot;https://argonne.wd1.myworkdayjobs.com/en-US/Argonne_Careers/job/Argonne-National-Laboratory/Postdoctoral-Appointee---Heterogeneity-in-High-Performance-Computing_408682&quot;&gt;Postdoctoral Appointee – Heterogeneity in High Performance Computing&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Contact: &lt;a href=&quot;bvideau@anl.gov&quot;&gt;Brice Videau&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Description: Heterogeneity in High Performance Computing (HPC) has never been greater, and most exascale systems deployed in the US will be accelerator-based systems. Understanding the performance of applications running on sizeable fractions of those machines will be a challenge, as the scale and complexity of those applications will be unprecedented. Nonetheless, the hybrid nature of these platforms offers a common opportunity to better understand how the applications interact with the accelerator (which is where most of the computing power will reside). Indeed, the Application Programming Interfaces (APIs) of those accelerators are well defined entry points that can be traced. CUDA or OpenCL are such APIs. By applying techniques derived from Model Centric Debugging on those APIs, it is possible to capture most of the accelerator-related context and events. At Argonne, in order to meet those challenges, we’ve been developing a collection of Model Centric Tracing tools that cover the APIs that will be encountered on exascale platforms. The tracers have already proven invaluable for profiling and debugging applications, capturing traces that can be reinjected in simulation frameworks, extracting kernels for replay allowing study and tuning in a sand-box, etc… We are looking for a post-doctoral appointee to perform research and development on the collection of tracers, as well as discover new and original applications for those tools.&lt;/p&gt;

&lt;h2 id=&quot;about-postdoc-positions-at-argonne-national-laboratory&quot;&gt;About postdoc positions at Argonne National Laboratory:&lt;/h2&gt;

&lt;p&gt;In addition to addressing such transformative challenges that arise at the intersection of HPC, big data analytics and machine learning,  postdocs have the opportunity to work closely with many domain experts to identify the requirements and bottlenecks of real-life scientific applications that address the needs of our society over the next decades. In general, you will be part of a vibrant and diverse research community from more than 100 countries. Our lab will host Aurora, one of the first Exascale supercomputers in the world, which you will have an opportunity to use for your experiments. In addition, you will have access to a large array of leading-edge experimental testbeds through the Joint Laboratory for System Evaluation (JLSE), which feature the latest technologies from top vendors like Intel, NVIDIA, AMD, CEREBRAS, etc.&lt;/p&gt;

&lt;h2 id=&quot;about-argonne-national-laboratory&quot;&gt;About Argonne National Laboratory:&lt;/h2&gt;

&lt;p&gt;As an equal employment opportunity and affirmative action employer, and in accordance with our core values of impact, safety, respect, integrity and teamwork, Argonne National Laboratory is committed to a diverse and inclusive workplace that fosters collaborative scientific discovery and innovation. In support of this commitment, Argonne encourages minorities, women, veterans and individuals with disabilities to apply for employment. Argonne considers all qualified applicants for employment without regard to age, ancestry, citizenship status, color, disability, gender, gender identity, genetic information, marital status, national origin, pregnancy, race, religion, sexual orientation, veteran status or any other characteristic protected by law. Argonne employees, and certain guest researchers and contractors, are subject to particular restrictions related to participation in Foreign Government Talent Recruitment Programs, as defined and detailed in United States Department of Energy Order 486.1. You will be asked to disclose any such participation in the application phase for review by Argonne’s Legal Department.&lt;/p&gt;
</description>
        <pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate>
        <link>https://jlesc.github.io/news/2021/04/27/postdoc-positions-at-anl/</link>
        <guid isPermaLink="true">https://jlesc.github.io/news/2021/04/27/postdoc-positions-at-anl/</guid>
      </item>
    
      <item>
        <title>13th JLESC Workshop</title>
        <description>&lt;p&gt;The 13th JLESC Workshop goes virtual, Dec 14 to 16, 2021.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Click &lt;a href=&quot;/events/13th-jlesc-workshop&quot;&gt;here&lt;/a&gt; for more information!&lt;/p&gt;
</description>
        <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
        <link>https://jlesc.github.io/news/2021/01/09/13th-workshop/</link>
        <guid isPermaLink="true">https://jlesc.github.io/news/2021/01/09/13th-workshop/</guid>
      </item>
    
      <item>
        <title>12th JLESC Workshop</title>
        <description>&lt;p&gt;The 12th JLESC Workshop will be held online from February 24 to 26, 2021.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Click &lt;a href=&quot;/events/12th-jlesc-workshop&quot;&gt;here&lt;/a&gt; for more information!&lt;/p&gt;
</description>
        <pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate>
        <link>https://jlesc.github.io/news/2020/12/11/12th-workshop/</link>
        <guid isPermaLink="true">https://jlesc.github.io/news/2020/12/11/12th-workshop/</guid>
      </item>
    
      <item>
        <title>11th JLESC Workshop</title>
        <description>&lt;p&gt;The 11th JLESC Workshop, the first virtual one in the history of the JLESC, will be held online from September 8 to 10, 2020.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Click &lt;a href=&quot;/events/11th-jlesc-workshop&quot;&gt;here&lt;/a&gt; for more information!&lt;/p&gt;
</description>
        <pubDate>Mon, 10 Aug 2020 00:00:00 +0000</pubDate>
        <link>https://jlesc.github.io/news/2020/08/10/11th-workshop/</link>
        <guid isPermaLink="true">https://jlesc.github.io/news/2020/08/10/11th-workshop/</guid>
      </item>
    
      <item>
        <title>10th JLESC Workshop</title>
        <description>&lt;p&gt;The 10th JLESC Workshop has been cancelled.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Click &lt;a href=&quot;/events/10th-jlesc-workshop&quot;&gt;here&lt;/a&gt; for more information!&lt;/p&gt;
</description>
        <pubDate>Tue, 30 Apr 2019 00:00:00 +0000</pubDate>
        <link>https://jlesc.github.io/news/2019/04/30/10th-workshop/</link>
        <guid isPermaLink="true">https://jlesc.github.io/news/2019/04/30/10th-workshop/</guid>
      </item>
    
      <item>
        <title>9th JLESC Workshop</title>
        <description>&lt;p&gt;The 9th JLESC Workshop will be held at the University of Tennessee, Knoxville, USA, from April 15 to 17, 2019.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Click &lt;a href=&quot;/events/9th-jlesc-workshop&quot;&gt;here&lt;/a&gt; for more information!&lt;/p&gt;
</description>
        <pubDate>Tue, 04 Dec 2018 00:00:00 +0000</pubDate>
        <link>https://jlesc.github.io/news/2018/12/04/9th-workshop/</link>
        <guid isPermaLink="true">https://jlesc.github.io/news/2018/12/04/9th-workshop/</guid>
      </item>
    
      <item>
        <title>Training course on intra-node performance bottlenecks</title>
        <description>&lt;p&gt;JSC is welcoming registrations for the training course “&lt;a href=&quot;http://www.fz-juelich.de/SharedDocs/Termine/IAS/JSC/EN/courses/2018/intranode-performance-2018.html&quot;&gt;From zero to hero: Understanding and fixing intra-node performance bottlenecks&lt;/a&gt;”!&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;In the first part of the training course we want to give insights in today’s CPU microarchitecture and apply this knowledge in the hands-on session. As a demonstrator we will use a simple Coulomb solver and improve the code step-by-step. We will start from a basic implementation and advance to an optimized version using hardware features like vectorization to increase performance.&lt;/p&gt;

&lt;p&gt;The exercises will also contain training on the use of open-source tools to measure and understand the achieved performance. Such optimizations, however, depend heavily on the targeted hardware and should not be part of the algorithmic layer of the code.&lt;/p&gt;

&lt;p&gt;In the second part we will present a detailed description of possible abstraction layers to hide such hardware-specifics and therefore maintain readability and maintainability. We will also discuss the overhead costs of our introduced abstraction and show compile-time SIMD configurations and corresponding performance results on different platforms.&lt;/p&gt;

&lt;p&gt;This advanced course is free of charge and intended for scientists/developers who want to understand performance-critical hardware features of modern CPUs (like SIMD, ILP, caches, out-of-order execution) and utilize these features in their code. See &lt;a href=&quot;http://www.fz-juelich.de/SharedDocs/Termine/IAS/JSC/EN/courses/2018/intranode-performance-2018.html&quot;&gt;here&lt;/a&gt; for details.&lt;/p&gt;
</description>
        <pubDate>Tue, 06 Feb 2018 00:00:00 +0000</pubDate>
        <link>https://jlesc.github.io/news/2018/02/06/training-course-at-jsc/</link>
        <guid isPermaLink="true">https://jlesc.github.io/news/2018/02/06/training-course-at-jsc/</guid>
      </item>
    
      <item>
        <title>Open JLESC PhD position at JSC</title>
        <description>&lt;p&gt;JSC has an open position for a &lt;a href=&quot;http://www.fz-juelich.de/SharedDocs/Stellenangebote/_common/dipldok/d026-2018-jsc.html&quot;&gt;PhD student&lt;/a&gt; in the field of C++ tasking approaches!&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Jülich Supercomputing Centre is recruiting a PhD student in the field
of computer science with a special focus on C++-based tasking approaches.&lt;/p&gt;

&lt;p&gt;The goal of this project is the extension and optimization of our C++
tasking framework for current and future HPC hardware as well as its
application to multigrid methods and the FMM. The project is
embedded into the interdisciplinary research setting of the Joint
Laboratory for Extreme Scale Computing (JLESC).&lt;/p&gt;

&lt;p&gt;Candidates should hold a university degree in the field of computer science or 
mathematics and should have profound understanding of C++
template metaprogramming, with no fear of numerical methods. Social
competence and good communication skills for collaborative work in and
with interdisciplinary teams are essential.&lt;/p&gt;

&lt;p&gt;The project runs for 3 years, for more information, please see &lt;a href=&quot;http://www.fz-juelich.de/SharedDocs/Stellenangebote/_common/dipldok/d026-2018-jsc.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
</description>
        <pubDate>Tue, 06 Feb 2018 00:00:00 +0000</pubDate>
        <link>https://jlesc.github.io/news/2018/02/06/phd-position-at-jsc/</link>
        <guid isPermaLink="true">https://jlesc.github.io/news/2018/02/06/phd-position-at-jsc/</guid>
      </item>
    
      <item>
        <title>2018 JSC Guest Student Programme on Scientific Computing</title>
        <description>&lt;p&gt;JSC welcomes applications for the &lt;a href=&quot;http://www.fz-juelich.de/ias/jsc/gsp&quot;&gt;2018 JSC Guest Student Programme on Scientific Computing&lt;/a&gt;!&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;In order to give students the opportunity to familiarize themselves
with various aspects of scientific computing as early as possible,
the Jülich Supercomputing Centre is once again organizing a
programme for guest students in the 2018 summer vacation. The
programme is supported by CECAM - Centre Europeen de Calcul Atomique 
and IBM. It targets students of science and engineering, computer science and
mathematics who have already completed their first degree but have
not yet finished their master’s course.&lt;/p&gt;

&lt;p&gt;The students will work together with local scientists on topics of
current interest in research and development. Depending on their
previous experience and interests, they will be involved in various
fields of work, for example:&lt;/p&gt;

&lt;p&gt;Computational Science, Applied Mathematics&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Modelling and simulation in physics, chemistry and biophysics&lt;/li&gt;
  &lt;li&gt;Techniques of parallel MD simulation&lt;/li&gt;
  &lt;li&gt;Modelling, simulation and data analysis in neuroscience&lt;/li&gt;
  &lt;li&gt;Parallel computational procedures in quantum chemistry and structural mechanics&lt;/li&gt;
  &lt;li&gt;Performance evaluation of parallel algorithms in linear algebra&lt;/li&gt;
  &lt;li&gt;Mathematical modelling, statistics and data mining&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Computer Architectures, GPU Computing&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;GPU-computing&lt;/li&gt;
  &lt;li&gt;High-speed data networks &amp;amp; data management&lt;/li&gt;
  &lt;li&gt;Programming models and performance portability&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;High-Performance Computing, Visualization&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Performance analysis and optimization of parallel programs&lt;/li&gt;
  &lt;li&gt;Programming of hierarchical parallel computer systems&lt;/li&gt;
  &lt;li&gt;Distributed applications, interactive control and visualization&lt;/li&gt;
  &lt;li&gt;Virtual reality techniques for visualizing scientific data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The programme will run for ten weeks from 6 August to 12 October 2018.
During this period JSC grants access to its supercomputers, including
the JURECA installation. The participants should be
familiar with the computational branch of their subject. In addition,
practical experience including at least a good knowledge of programming
with C, C++, Python or Fortran on Linux systems should be present.&lt;/p&gt;

&lt;p&gt;More information: &lt;a href=&quot;http://www.fz-juelich.de/ias/jsc/gsp&quot;&gt;http://www.fz-juelich.de/ias/jsc/gsp&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Application deadline: &lt;strong&gt;25 March 2018&lt;/strong&gt;&lt;/p&gt;
</description>
        <pubDate>Tue, 06 Feb 2018 00:00:00 +0000</pubDate>
        <link>https://jlesc.github.io/news/2018/02/06/gsp-at-jsc/</link>
        <guid isPermaLink="true">https://jlesc.github.io/news/2018/02/06/gsp-at-jsc/</guid>
      </item>
    
      <item>
        <title>UTK becomes Associate Partner</title>
        <description>&lt;p&gt;Starting from January 1, 2018, the &lt;a href=&quot;https://www.utk.edu&quot;&gt;University of Tennessee&lt;/a&gt;, represented by the  &lt;a href=&quot;http://www.icl.utk.edu/&quot;&gt;Innovative Computing Laboratory&lt;/a&gt; (ICL) at the University of Tennessee (UTK), becomes new Associate Partner of the JLESC.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;At the University of Tennessee, there are a number of groups working on extreme scale computing.&lt;/p&gt;

&lt;p&gt;The Innovative Computing Laboratory aspires to be a world leader in enabling technologies and software for scientific computing. Its vision is to provide high performance tools to tackle science’s most challenging problems and to play a major role in the development of standards for scientific computing in general.&lt;/p&gt;

&lt;p&gt;ICL is a research laboratory in the College of Engineering at the University of Tennessee and serves as the cornerstone laboratory of the Center for Information Technology Research (CITR), one of UT’s nine Centers of Excellence.&lt;/p&gt;

&lt;p&gt;Welcome, ICL!&lt;/p&gt;
</description>
        <pubDate>Wed, 03 Jan 2018 00:00:00 +0000</pubDate>
        <link>https://jlesc.github.io/news/2018/01/03/icl-associate-partner/</link>
        <guid isPermaLink="true">https://jlesc.github.io/news/2018/01/03/icl-associate-partner/</guid>
      </item>
    
  </channel>
</rss>
