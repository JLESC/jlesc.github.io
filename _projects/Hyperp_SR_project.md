---
layout: page_project
title: Architecture and Hyperparameter Search for Super-Resolution Networks Operating on Medical Images
date: 2022-12-15
updated: 2022-12-15
navbar: Research
subnavbar: Projects
project_url:
status: starting
topics:
  - numerics
  - apps
keywords:
  - hyperparameter optimization 
  - neural network architecture
  - medical images 
  - super-resolution
  - CFD
head: liu_x
members:
  - lintermann_a
  - ruettgers_m
  - aach_m
  - balaprakash_p
  
---


## Research topic and goals
Diagnosis of pathologies in the human respiratory system have recently included results of computational fluid dynamics (CFD) simulations, which allow numerical quantification of respiratory flows by the pressure loss, the temperature distribution, etc. {% cite lintermann2013fluid %}. Highly resolved computational meshes based on computer tomography (CT) images are necessary to accurately simulate the respiratory flow. However, clinical CT image resolution is often limited by radiation dose and acquisition time. Super-resolution networks (SRNs) have the potential to increase the resolution of images a posterior the recording. In this project, SRNs are employed and optimized to recover high-resolution (HR) from low-resolution (LR) CT images. SRNs predictions are validated by comparing the results of CFD simulations, carried out with the highly scalable lattice-Boltzmann method (LBM) {% cite lintermann2020zonal %}. 

The performance of SRNs is highly dependent on the hyperparameters, either related to model architecture or optimizer. Finding the optimal architectures and hyperparameters is limited by computational resources as the search space is often too large to explore exhaustively. The DeepHyper (DH) framework aims to tackle these challenges by employing an asynchronous Bayesian optimization (BO) approach for hyperparameter and architecture search at HPC scale {% cite balaprakash2018deephyper %}. Another limitation of existing SRNs is that they provide forecasts without any uncertainty estimates. In this project, the developers will build on DeepHyper’s automated deep ensemble for uncertainty quantification capability (AutoDEUQ). DeepHyper/AutoDEUQ estimates aleatoric and epistemic uncertainties by: automatically generating a catalog of neural networks models through joint neural architecture and hyperparameter search, wherein each model is trained to model the distribution of the data; and selecting a set of high-performing models to construct the ensembles, and estimating aleatoric and epistemic uncertainties from the generated model ensembles.

It is the aim of the proposed cooperation to investigate architecture and hyperparameter search algorithms for SRNs for enhancing resolution of CT images. This includes performance, scalability, and accuracy analyses of DH. The findings will be juxtaposed to those obtained employing similar tools for distributed hyperparameter optimization such as Ray Tune. JSC brings in its knowledge about SRNs, medical data, and CFD simulations, and ANL contributes with its expertise in architecture and hyperparameter search in general, and in employing DH on HPC systems.

## Results for 2021/2022
The dataset consists of CT head recording from 65 patients. HR images were 1mm thick axial slices with matrix size of 512*512. LR images were generated by taking average of 3 adjacent HR slices, and the middle HR slice was taken as ground truth. The architecture of original U-net {% cite ronneberger2015u %} was built with batch normalization, trained with LR image as input and middle HR slice as label. For comparison, resolution was also resumed using spline interpolation. The trained network was tested on 3 patients, and the U-net prediction outperforms interpolation results by comparing peak signal-to-noise ratio. Surfaces were generated using U-net prediction, HR, LR images and interpolation results. LBM simulation was carried out {% cite lintermann2020zonal %} for one of the patients and the averaged pressure loss between inlets and outlet was 9.695 Pa for HR, 8.965 Pa (-8.5 %) for LR, 7.706 Pa (-20.5 %) for interpolated, 9.849 Pa (+1.6 %) for U-net prediction. The above results are used as baseline for the current project.

## Visits and meetings
* 28-30, Sep 2022: Mario Rüttgers participated in 14th JLESC Workshop at The University of Illinois at Urbana-Champaign and started the collaboration
* Project members had online kick-off meetings for detailed plans, and meet regularly to discuss progress

## Impact and publications
{% bibliography --cited --file jlesc.bib %}

## Future plans
* Collection of best-practice methods for architecture and hyperparameter search for SRNs using different frameworks
* Deployment of DH as a standard module for HPC systems at JSC
* Manuscript for the special issue journal publication in the framework of the 15th JLESC workshop in Bordeaux, France

## References
{% bibliography --file external/Hyperp_SR_project.bib %}
